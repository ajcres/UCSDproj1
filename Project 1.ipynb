#Placeholder website: https://sites.google.com/view/ucsdpostreader/home

#This is the most common 100 words in the english language
normieWords = ["the","of","and","a","to","in","is","you","that","it","he","was","for","on","are","as","with","his","they","i","at","be","this","have","from","or","one","had","by","word","but","not","what","all","were","we","when","your","can","said","there","use","an","each","which","she","do","how","their","if","will","up","other","about","out","many","then","them","these","so","some","her","would","make","like","him","into","time","has","look","two","more","write","go","see","number","no","way","could","people","my","than","first","water","been","call","who","oil","its","now","find","long","down","day","did","get","come","made","may","part"]

#setting up the twitter search abilities
import twitter
api = twitter.Api(consumer_key='dbACwwWs67Xlj8HXtY5wC8c30', consumer_secret='Y2JtxeQAwn5BMUgxAffVfbcfVa9arP8a0qohaLjWJtKkmPmPfK', access_token_key='1129404921340727301-pXeBhw4xYNrscF0ELKnpOn22wS0nkP',access_token_secret='9dNXCwVG9rn3oooq5ZsgCdqM4HXvKvv5avhlMIZ584c3p')

#REMOVE PERIODS AT THE END OF SENTANCES

def LookAt(pl,nw): #pl is the list of posts in string format and nw is the list of the most commmon english words
    #list of hashtags
    hashes = []
    #list of @s
    ats = []
    #list of all words
    aWords = []
    #looks at each post's content
    for post in pl:
        #list of the words in the post
        postWords = []
        #splits the post into words and removes the most common english words
        for word in post.lower().split():
            if word not in nw:
                postWords.append(word)
        
        #The following code removes/changes/arranges the text in th posts, it has to do things one at a time as there might be repeat errors/problems to deal with
        
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if word[0] == '#':
                hashes.append(word)
                postWords.remove(word)
        #removes rt and &amp as it shows up on posts and is not an actual "word used"
        for word in postWords:
            if word == 'rt' or word == '&amp':
                postWords.remove(word)
        #removes grammer things
        for word in postWords:
            tw = ""
            for ch in word:
                if not (ord(ch) <65 or (ord(ch) >90 and ord(ch) <97) or ord(ch) >122):
                    tw+=ch
            if len(tw) == 0:
                postWords.remove(word)
            else:
                word = tw
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if '@' in word:
                ats.append(word)
                postWords.remove(word)
        #removes emoji/non-ascii words
        for word in postWords:
            for ch in word:
                if ch > "\x7F":
                    postWords.remove(word)
                    break
        #removes links
        for word in postWords:
            if 'http' in word or 'bit.ly' in word:
                postWords.remove(word)
        #collects all of the words together
        for word in postWords:
            aWords.append(word)
    #prints the most used hashtags
    sortWords(hashes, "hashtags",1)
    #prints the most 'atted' people
    sortWords(ats, "mentions",2)
    #prints the most used words
    sortWords(aWords, "words",4)

def sortWords (swl,typ,division): #swl is the list of words, typ is the name of the word for printing, division is the fraction of numbers to print
    #check if the person used any of the words
    if len(swl)>0:
        #code that creates 2d array with the words and the number of them
        hl = []
        for hn1 in range(len(swl)):
            boo = True
            for hn2 in range(len(hl)):
                if swl[hn1] == hl[hn2][0]:
                    boo = False
                    hl[hn2][1]+=1
            if boo:
                hl.append([swl[hn1],1])
        
        #cleans up the list to remove artifacts from the above code
        for hn1 in range(len(hl)):
            if hl[hn1][0] == '':
                hl.pop(hn1)
                break
        #decides on the number of words to print
        hashToP = (len(hl))//division
        #setup for sorting by the second number
        def sortSecond(ppp):
            return ppp[1]
        #sorts in ascending order by the second value in the double arrays
        hl.sort(key = sortSecond, reverse = True)
        #prints the highest used words and their types
        print("\nCommonly used "+typ+":")
        bole = False
        #if there is over 100 correct words, set it to print 100 max
        if hashToP>100:
            hashToP = 100
        #for loop for printing the words
        for eee in range(hashToP):
            #only prints words that are repeated more than once
            if hl[eee][1] > 1:
                print(hl[eee][0] +"\tappears "+ str(hl[eee][1]) + " times")
                bole = True
        #this prints if no words were repeated/printed
        if not bole:
            print("-No repeated "+typ+" found")
    else:
        print("This person has not used any "+typ)

#gets list of posts from twitter user
TempTw = api.GetUserTimeline(screen_name=input("Twitter username"), count = int(input("Number of posts to search")))
#turns list of "Status" class into dictionary to be able to use it
TwList = [i.AsDict() for i in TempTw]
postList = []
#takes the dictionary and makes a list of the post's strings out of its
for z in TwList:
    postList.append(z['text'])
#runs the main analysis code
LookAt(postList,normieWords)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import twitter
#Placeholder website: https://sites.google.com/view/ucsdpostreader/home

#This is the most common 100 words in the english language
normieWords = ["me","say","just","things", "why", "want","the","of","and","a","to","in","is","you","that","it","he","was","for","on","are","as","with","his","they","i","at","be","this","have","from","or","one","had","by","word","but","not","what","all","were","we","when","your","can","said","there","use","an","each","which","she","do","how","their","if","will","up","other","about","out","many","then","them","these","so","some","her","would","make","like","him","into","time","has","look","two","more","go","see","number","no","way","could","people","my","than","first","been","call","who","its","now","find","long","down","day","did","get","come","made","may","part", "i'm", "we're", "they're", "me"]

#setting up the twitter search abilities
import twitter
api = twitter.Api(consumer_key='dbACwwWs67Xlj8HXtY5wC8c30', consumer_secret='Y2JtxeQAwn5BMUgxAffVfbcfVa9arP8a0qohaLjWJtKkmPmPfK', access_token_key='1129404921340727301-pXeBhw4xYNrscF0ELKnpOn22wS0nkP',access_token_secret='9dNXCwVG9rn3oooq5ZsgCdqM4HXvKvv5avhlMIZ584c3p')

#REMOVE PERIODS AT THE END OF SENTENCES

def delSymbols(string):
    liss = [ord(x) for x in string]
    liss = [y for y in liss if not(y < 64 or (y > 90 and y < 97) or y > 122)]
    return ''.join([chr(c) for c in liss])
def delSymbolsArr(arr):
    for x in range(len(arr)):
        arr[x] = delSymbols(arr[x])
def delOneLen(arr):
    for x in arr:
        if len(x) <= 1:
            arr.remove(x)
def LookAt(pl,nw): #pl is the list of posts in string format and nw is the list of the most commmon english words
    #list of hashtags
    hashes = []
    #list of @s
    ats = []
    #list of all words
    aWords = []
    #looks at each post's content
    for post in pl:
        #list of the words in the post
        postWords = []
        #splits the post into words and removes the most common english words
        for word in post.lower().split():
            if word not in nw:
                postWords.append(word)
        
        #The following code removes/changes/arranges the text in the posts, it has to do things one at a time as there might be repeat errors/problems to deal with
        
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if word[0] == '#':
                hashes.append(word)
                postWords.remove(word)
        #removes rt and &amp as it shows up on posts and is not an actual "word used"
        for word in postWords:
            if word == 'rt' or word == '&amp' or word == "&amp;":
                postWords.remove(word)
        #removes grammar things
        for word in postWords:
            tw = ""
            for ch in word:
                if not (ord(ch) <65 or (ord(ch) >90 and ord(ch) <97) or ord(ch) >122):
                    tw += ch
            if len(tw) == 0:
                postWords.remove(word)
            else:
                word = tw
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if '@' in word:
                ats.append(word)
                postWords.remove(word)
        #removes emoji/non-ascii words
        for word in postWords:
            for ch in word:
                if ch > "\x7F":
                    postWords.remove(word)
                    break
        #removes links
        for word in postWords:
            if 'http' in word or 'bit.ly' in word:
                postWords.remove(word)
        #removes symbols
        delSymbolsArr(postWords)
        #removes one letter words
        delOneLen(postWords)
        #collects all of the words together
        for word in postWords:
            aWords.append(word)
    #prints the most used hashtags
    sortWords(hashes, "hashtags",1)
    #prints the most 'atted' people
    sortWords(ats, "mentions",2)
    #prints the most used words
    sortWords(aWords, "words",4)

def sortWords (swl,typ,division): #swl is the list of words, typ is the name of the word for printing, division is the fraction of numbers to print
    #check if the person used any of the words
    if len(swl) > 0:
        #code that creates 2d array with the words and the number of them
        hl = []
        for hn1 in range(len(swl)):
            boo = True
            for hn2 in range(len(hl)):
                if swl[hn1] == hl[hn2][0]:
                    boo = False
                    hl[hn2][1]+=1
            if boo:
                hl.append([swl[hn1],1])
        
        #cleans up the list to remove artifacts from the above code
        for hn1 in range(len(hl)):
            if hl[hn1][0] == '':
                hl.pop(hn1)
                break
        #decides on the number of words to print
        hashToP = (len(hl))//division
        #setup for sorting by the second number
        def sortSecond(ppp):
            return ppp[1]
        #sorts in ascending order by the second value in the double arrays
        hl.sort(key = sortSecond, reverse = True)
        #prints the highest used words and their types
        print("\nCommonly used "+typ+":")
        bole = False
        #if there is over 100 correct words, set it to print 100 max
        if hashToP>100:
            hashToP = 100
        #for loop for printing the words
        for eee in range(hashToP):
            #only prints words that are repeated more than once
            if hl[eee][1] > 1:
                print(hl[eee][0] +"\tappears "+ str(hl[eee][1]) + " times")
                bole = True
        #this prints if no words were repeated/printed
        if not bole:
            print("-No repeated "+typ+" found")
    else:
        print("This person has not used any "+typ)

#gets list of posts from twitter user
TempTw = api.GetUserTimeline(screen_name=input("Twitter username:\t"), count = int(input("Number of posts to search:\t")))
#turns list of "Status" class into dictionary to be able to use it
TwList = [i.AsDict() for i in TempTw]
postList = []
#takes the dictionary and makes a list of the post's strings out of its
for z in TwList:
    postList.append(z['text'])
#runs the main analysis code
LookAt(postList,normieWords)
