#Placeholder website: https://sites.google.com/view/ucsdpostreader/home

#This is the most common 100 words in the english language
normieWords = ["the","of","and","a","to","in","is","you","that","it","he","was","for","on","are","as","with","his","they","i","at","be","this","have","from","or","one","had","by","word","but","not","what","all","were","we","when","your","can","said","there","use","an","each","which","she","do","how","their","if","will","up","other","about","out","many","then","them","these","so","some","her","would","make","like","him","into","time","has","look","two","more","write","go","see","number","no","way","could","people","my","than","first","water","been","call","who","oil","its","now","find","long","down","day","did","get","come","made","may","part"]

#setting up the twitter search abilities
import twitter
api = twitter.Api(consumer_key='dbACwwWs67Xlj8HXtY5wC8c30', consumer_secret='Y2JtxeQAwn5BMUgxAffVfbcfVa9arP8a0qohaLjWJtKkmPmPfK', access_token_key='1129404921340727301-pXeBhw4xYNrscF0ELKnpOn22wS0nkP',access_token_secret='9dNXCwVG9rn3oooq5ZsgCdqM4HXvKvv5avhlMIZ584c3p')

def LookAt(pl,nw): #pl is the list of posts in string format and nw is the list of the most commmon english words
    #list of hashtags
    hashes = []
    #list of @s
    ats = []
    #list of all words
    aWords = []
    #looks at each post's content
    for post in pl:
        #list of the words in the post
        postWords = []
        #splits the post into words and removes the most common english words
        for word in post.lower().split():
            if word not in nw:
                postWords.append(word)
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if word[0] == '#':
                hashes.append(word)
                postWords.remove(word)
        #removes hashtags and adds them to the hashtag list
        for word in postWords:
            if '@' in word:
                ats.append(word)
                postWords.remove(word)
        #removes emoji/non-ascii words
        for word in postWords:
            for ch in word:
                if ch > "\x7F":
                    postWords.remove(word)
                    break
        #removes links
        for word in postWords:
            if 'http' in word or 'bit.ly' in word:
                postWords.remove(word)
        #collects all of the words together
        for word in postWords:
            aWords.append(word)
    #prints the most used hashtags
    sortWords(hashes, "hashtags",1)
    #prints the most 'atted' people
    sortWords(ats, "mentions",2)
    #prints the most used words
    sortWords(aWords, "words",4)

def sortWords (swl,typ,division):
    #code that creates 2d array with the words and the number of them
    hl = []
    for hn1 in range(len(swl)):
        boo = True
        for hn2 in range(len(hl)):
            if swl[hn1] == hl[hn2][0]:
                boo = False
                hl[hn2][1]+=1
        if boo:
            hl.append([swl[hn1],1])
        
    #cleans up the list to remove artifacts from the above code
    for hn1 in range(len(hl)):
        if hl[hn1][0] == '':
            hl.pop(hn1)
            break
    #decides on the number of wordss to print
    hashToP = (len(hl))//division
    #setup for sorting by the second number
    def sortSecond(ppp):
        return ppp[1]
    #sorts in ascending order by the second value in the double arrays
    hl.sort(key = sortSecond, reverse = True)
    #prints the highest used words and their types
    print("\nCommonly used "+typ+":")
    for eee in range(hashToP):
        if hl[eee][1] > 1:
            print(hl[eee][0] +"\tappears "+ str(hl[eee][1]) + " times")

#gets list of posts from twitter user
TempTw = api.GetUserTimeline(screen_name=input("Twitter username"), count = int(input("Number of posts to search")))
#turns list of "Status" class into dictionary to be able to use it
TwList = [i.AsDict() for i in TempTw]
postList = []
#takes the dictionary and makes a list of the post's strings out of its
for z in TwList:
    postList.append(z['text'])
#runs the main analysis code
LookAt(postList,normieWords)

